---
title: "Plankton PDFs transformations"
output: html_notebook
---

Using a R Markdown Notebook to explore the transformation of plankton probability density functions (PDFs) to two linearly conserved variables (Biomass and total organism count)

Sample data: Luo et al. unpublished. Phytoplankton and zooplankton individual lengths from an in-situ imaging system. Data subsetted from original.

```{r}
# libraries
library(ggplot2)
library(plyr)

# set working directory
# setwd("/Users/jluo/Documents/NCAR/models/plankton-pdf")

# functions for geometric mean and sd
gm_mean = function(x, na.rm=TRUE, na.exclude=FALSE){
  if(na.exclude){
    x <- x[which(!is.na(x))]
    x <- x[x>0]
    res <- exp(mean(log(x), na.rm=na.rm))
    return(res)
  } else {
    x <- x[x>0]
    res <- exp(mean(log(x), na.rm=na.rm))
    return(res)
  }
}

gm_sd <- function(x, na.rm = TRUE, ...)
{
  exp(sd(log(x, ...), na.rm = na.rm, ...))
}


```

```{r}
d <- read.table("data/phyto_zoo_lengths_subset.txt", sep = "", header=TRUE)
d <- d[which(d$len_px > 0),]

d$type <- ifelse(d$type==1, "phyto", "zoo")
d$len_mm <- d$len_px / 15.1704

print(str(d))
print(head(d, 3))
```


```{r}
plot(density(d$len_mm), main = "PDF of plankton size distributions (untransformed)", xlab="Organism lengths (mm), N = 302585")
```

Organism lengths are then converted to biomass according to a general allometric relationship from Rodriguez and Mullin (1986):
log Biomass = 2.23 log ESD - 5.58

```{r}
len_ug <- d$len_mm * 1000
B_ug <- 2.23 * log10(len_ug) - 5.58 

d$biomass_ugC <- B_ug #/ 1000

# lengths under 0.318 mm result in a negative biomass, exclude those from this analysis
d <- d[d$len_mm >= 0.318,]

plot(density(d$biomass_ugC), main="PDF of individual organism biomass (micrograms Carbon)", xlab="Organism biomass (micrograms C)")
```

Convert biomass to a normalized biomass spectrum. Patt and Denman (1977) proposed the "normalized biomass spectrum (NBS)" in which biomass concentration per size interval is divided by the linear width of the interval and displayed on a logarithmic ordinate.

Convert to equal bins on a log-scale (thus, bins should be exponentially increasing in size on a non-log scale)
```{r}
log_biomass <- sort(unique(log2(d$biomass_ugC)))
# add the last element to ensure the breaks do not get cut off
log_biomass <- c(log_biomass, round(max(log_biomass), 2) + 0.01) 


# create the levels
log_cuts = data.frame(levels=levels(cut(log_biomass, breaks = 20))) #breaks=6


# parse the levels into min and max
# replace every punctuation mark except [,.-] by an empty string
min_max <- unlist(strsplit(gsub("(?![,.-])[[:punct:]]", "", 
           as.character(log_cuts$levels), perl=TRUE), ","))
log_cuts$log_min <- as.numeric(min_max[seq(1, length(min_max), by=2)])
log_cuts$log_max <- as.numeric(min_max[seq(2, length(min_max), by=2)])

log_cuts$min <- 2^(log_cuts$log_min)
log_cuts$max <- 2^(log_cuts$log_max)
```

```{r}
print(head(log_cuts, 3))
print(tail(log_cuts, 3))
```
 
```{r}
breaks <- c(log_cuts$min[1], log_cuts$max)

d$bin <- cut(d$biomass_ugC, breaks=breaks) # factor

# calculate the linear length of each bin
min_max <- unlist(strsplit(gsub("(?![,.-])[[:punct:]]", "", 
           as.character(levels(d$bin)), perl=TRUE), ","))
min <- as.numeric(min_max[seq(1, length(min_max), by=2)])
max <- as.numeric(min_max[seq(2, length(min_max), by=2)])

bin_lengths <- max - min
bin_meanwt <- apply(cbind(min, max), 1, gm_mean)

ggplot(data=data.frame(bin_lengths=bin_lengths, n=1:length(bin_lengths))) + geom_line(aes(y=bin_lengths, x=n)) + 
  labs(title="Size of bins (increasing due to log transformation)", xlab="Size of bins (ug C)", ylab="sequential bin number")
```

Binning the data into size bins

```{r}
# assign bin lengths to bins
d$bin_lengths <- bin_lengths[as.numeric(d$bin)]
d$bin_meanwt <- bin_meanwt[as.numeric(d$bin)]

# collect bins together, calculate a mean/sum biomass per bin and divide by the width of the interval
dd <- ddply(d, ~bin+type, function(x){
  len_px <- gm_mean(x$len_px)
  len_mm <- gm_mean(x$len_px)
  biomass_ugC_mean <- gm_mean(x$biomass_ugC)
  biomass_ugC_sum <- sum(x$biomass_ugC)
  n <- nrow(x)
  
  return(data.frame(n, len_px, len_mm, biomass_ugC_mean, biomass_ugC_sum, 
                    bin_length = unique(x$bin_length), bin_meanwt = unique(x$bin_meanwt)))
})

head(dd)
```

***
Plot of normalized biomass. **_The problem is that I am not sure how to get this PDF to be linear._**

```{r}
dd$norm_biomass <- dd$biomass_ugC_sum / dd$bin_meanwt
plot(density(dd$norm_biomass), main="PDF of normalized biomass", xlab="Normalized biomass")
```

The log-normalized biomass is also not linear.

```{r}
plot(density(log10(dd$norm_biomass)), main="PDF of Log-normalized Biomass", xlab="Log normalized biomass")
```

```{r}
ggplot(dd) + geom_point(aes(x=log10(dd$bin_meanwt), y=log10(dd$biomass_ugC_sum), colour=type))
```

```{r}
# check
print(bin_lengths / bin_meanwt)
plot(bin_lengths~bin_meanwt)
```

Reverse Engineering the particle size distribution
========

```{r}
log_x <- seq(from = -5,to = 10, 1) #log bins
x <- 2^log_x 

log_norm_biomass = -log_x
plot(log_norm_biomass ~ log_x, type="l")
```

```{r}
norm_biomass = 2^(log_norm_biomass * x)

plot(norm_biomass ~ x, type="l")
```

***
**Notes on R Notebooks**

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file).
